{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, TensorFlow!'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(10)\n",
    "b = tf.constant(32)\n",
    "print(sess.run(a + b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "from theano.ifelse import ifelse\n",
    "from theano import function\n",
    "\n",
    "# Define Variables\n",
    "x = T.vector('x')\n",
    "w = T.vector('w')\n",
    "b = T.scalar('b')\n",
    "\n",
    "# Define Mathematical expression \n",
    "z = T.dot(x,w) + b\n",
    "actFn = ifelse(T.lt(z,0),0,1)\n",
    "\n",
    "andGateImpl = function([x,w,b], actFn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In this block we defined the weights manually\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy\n",
    "from theano.ifelse import ifelse\n",
    "from theano import function\n",
    "\n",
    "# Declare variables\n",
    "x = T.vector('x')\n",
    "w = T.vector('w')\n",
    "b = T.scalar('b')\n",
    "\n",
    "# Define Math Func\n",
    "z = T.dot(x,w)+b\n",
    "actFn = ifelse(T.lt(z,0),0,1)\n",
    "\n",
    "neuron = function([x,w,b],actFn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Define Inputs\n",
    "inputs = [\n",
    "    [0,0],\n",
    "    [0,1],\n",
    "    [1,0],\n",
    "    [1,1]\n",
    "    ]\n",
    "weights = [1,1]\n",
    "bias = -1.5\n",
    "\n",
    "for i in range(len(inputs)):\n",
    "    t = inputs[i]\n",
    "    out = neuron(t,weights,bias)\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# In this next block we defined the weights as a shared variable, so that they can be updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.ifelse import ifelse\n",
    "import numpy as np\n",
    "\n",
    "#Define variables:\n",
    "x = T.vector('x')\n",
    "w = theano.shared(np.array([1,1]))\n",
    "b = theano.shared(-1.5)\n",
    "\n",
    "#Define mathematical expression:\n",
    "z = T.dot(x,w)+b\n",
    "a = ifelse(T.lt(z,0),0,1)\n",
    "\n",
    "neuron = theano.function([x],a)\n",
    "\n",
    "#Define inputs and weights\n",
    "inputs = [\n",
    "    [0, 0],\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [1, 1]\n",
    "]\n",
    "\n",
    "#Iterate through all inputs and find outputs:\n",
    "for i in range(len(inputs)):\n",
    "    t = inputs[i]\n",
    "    out = neuron(t)\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorType(float64, vector)>\n",
      "Elemwise{add,no_inplace}.0\n"
     ]
    }
   ],
   "source": [
    "# In this block we will use backpropogation to update the weigths\n",
    "import theano \n",
    "import theano.tensor as T\n",
    "from theano.ifelse import ifelse\n",
    "import numpy as np\n",
    "from random import random \n",
    "from theano import function\n",
    "\n",
    "# Define variables\n",
    "x = T.matrix('x')\n",
    "w = theano.shared(np.array([random(),random()]))\n",
    "print(w)\n",
    "b = theano.shared(1.)\n",
    "learning_rate = 0.01\n",
    "a_hat = T.vector('a_hat')  # Actual output\n",
    "\n",
    "# Define Mathematical Expressions\n",
    "z = T.dot(x,w)+b\n",
    "print(z)\n",
    "a = 1/(1+T.exp(-z))  # Check if the activation function is correct. \n",
    "                       # For regression we do hθ(x) = (θT x), but for classification we do hθ(x) = g((θT x))\n",
    "\n",
    "cost = -(a_hat*T.log(a)+(1-a_hat)*T.log(1-a)).sum()\n",
    "\n",
    "# Define gradient \n",
    "dw,db = T.grad(cost,[w,b])\n",
    "\n",
    "# Update weights\n",
    "train = function(inputs = [x,a_hat], \n",
    "                 outputs = [a,cost],                    ## Syntax is tricky !! Be careful. Don't forget '[]', ',' etc.\n",
    "                updates = [\n",
    "                    [w,w - learning_rate*dw],\n",
    "                    [b,b - learning_rate*db]\n",
    "                ]\n",
    "        ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The outputs of the NN are:\n",
      "The output for x1=0 | x2=0 is 0.00\n",
      "The output for x1=0 | x2=1 is 0.02\n",
      "The output for x1=1 | x2=0 is 0.02\n",
      "The output for x1=1 | x2=1 is 0.98\n"
     ]
    }
   ],
   "source": [
    "# Define input and the output\n",
    "inputs = [\n",
    "    [0,0],\n",
    "    [0,1],\n",
    "    [1,0],\n",
    "    [1,1]\n",
    "]\n",
    "\n",
    "outputs = [0,0,0,1]\n",
    "\n",
    "# Integrate through outputs and and find outputs. \n",
    "cost = []                         # Be careful of Syntax!!\n",
    "for iterations in range(30000):\n",
    "    pred, cost_iter = train(inputs,outputs)\n",
    "    cost.append(cost_iter)\n",
    "    \n",
    "# Print output\n",
    "print(\"The outputs of the NN are:\")\n",
    "for i in range(len(inputs)):\n",
    "    str_temp = 'The output for x1=%d | x2=%d is %.2f' % (inputs[i][0],inputs[i][1],pred[i])\n",
    "    print(str_temp)\n",
    "\n",
    "# Plot the cost function w.r.t. iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01364751  0.1709592   0.17068661  0.75414514]\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy as p\n",
    "from random import random\n",
    "from theano.ifelse import ifelse\n",
    "from theano import function\n",
    "\n",
    "# Declare the variable\n",
    "x = T.matrix('x')\n",
    "w = theano.shared(np.array([random(),random()]))\n",
    "b = theano.shared(1.)\n",
    "learning_rate = 0.01\n",
    "a_hat = T.vector('a_hat')\n",
    "\n",
    "# Define mathematical expressions\n",
    "z = T.dot(x,w)+b\n",
    "a = 1/(1+T.exp(-z))\n",
    "cost = -(a_hat*T.log(a)+(1-a_hat)*T.log(1-a)).sum()\n",
    "wd,bd = T.grad(cost,[w,b])\n",
    "\n",
    "train = function(\n",
    "    inputs = [x,a_hat],\n",
    "    outputs = [a,cost],\n",
    "    updates = [\n",
    "        [w,w-learning_rate*wd],\n",
    "        [b,b-learning_rate*bd]\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the input and uotput\n",
    "inputs = [\n",
    "    [0,0], [0,1], [1,0], [1,1]\n",
    "]\n",
    "outputs = [0,0,0,1]\n",
    "\n",
    "# Define the iterations\n",
    "cost = []\n",
    "for iterations in range(2000):\n",
    "    pred, cost_iter = train(inputs,outputs)\n",
    "    cost.append(cost_iter)\n",
    "\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I find this similar to a cooking activity\n",
    "# Variables are your spices. Weights are the quantity of your variables\n",
    "# Activator function is like the raw vegetables. If I use beans+potato I get that vegetable. If I use \n",
    "# I decide of doing 10 iterations. Each time I will change the quantity of spices. \n",
    "# If salt is on the lower side, I will keep adding it until it reaches perfect level.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
